{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df = pd.read_csv(\"english_text.csv\")\n",
    "hinglish_df = pd.read_csv(\"hinglish_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_df[\"label\"] = 0\n",
    "hinglish_df[\"label\"] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_df = english_df.append(hinglish_df)\n",
    "random_mixed_df = mixed_df.sample(len(mixed_df)).values\n",
    "random_mixed_df= random_mixed_df[:,1:]\n",
    "\n",
    "labels = []\n",
    "texts= []\n",
    "for i in range(len(random_mixed_df)):\n",
    "    \n",
    "    texts.append(random_mixed_df[i][0])\n",
    "    labels.append(random_mixed_df[i][1])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_counts = Counter()\n",
    "hinglish_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "    r =texts[i].split(' ')\n",
    "    if(labels[i] == 0):\n",
    "        english_counts.update(r)\n",
    "    else:\n",
    "        hinglish_counts.update(r)\n",
    "    \n",
    "    total_counts.update(r)\n",
    "    r=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49536"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_counts['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_0 = []\n",
    "for sentence in texts:\n",
    "    temp=[]\n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    for x in words:\n",
    "        temp.append(total_counts[x])\n",
    "    \n",
    "    layer_0.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.preprocessing.sequence.pad_sequences(layer_0,value=0,padding='post',maxlen=971)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59176"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          916656    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 916,945\n",
      "Trainable params: 916,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(total_counts)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size,16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16,activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1,activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = labels[:10000]\n",
    "partial_y_train = labels[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49176, 971)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 49176 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "49176/49176 [==============================] - 8s 172us/sample - loss: 0.5789 - acc: 0.9154 - val_loss: 0.4304 - val_acc: 0.9260\n",
      "Epoch 2/40\n",
      "49176/49176 [==============================] - 8s 169us/sample - loss: 0.3166 - acc: 0.9241 - val_loss: 0.2522 - val_acc: 0.9260\n",
      "Epoch 3/40\n",
      "49176/49176 [==============================] - 8s 169us/sample - loss: 0.2478 - acc: 0.9242 - val_loss: 0.2372 - val_acc: 0.9265\n",
      "Epoch 4/40\n",
      "49176/49176 [==============================] - 8s 172us/sample - loss: 0.2333 - acc: 0.9250 - val_loss: 0.2201 - val_acc: 0.9278\n",
      "Epoch 5/40\n",
      "49176/49176 [==============================] - 9s 175us/sample - loss: 0.2131 - acc: 0.9281 - val_loss: 0.1962 - val_acc: 0.9343\n",
      "Epoch 6/40\n",
      "49176/49176 [==============================] - 9s 176us/sample - loss: 0.1854 - acc: 0.9377 - val_loss: 0.1667 - val_acc: 0.9440\n",
      "Epoch 7/40\n",
      "49176/49176 [==============================] - 9s 175us/sample - loss: 0.1575 - acc: 0.9484 - val_loss: 0.1406 - val_acc: 0.9539\n",
      "Epoch 8/40\n",
      "49176/49176 [==============================] - 9s 174us/sample - loss: 0.1345 - acc: 0.9564 - val_loss: 0.1201 - val_acc: 0.9611\n",
      "Epoch 9/40\n",
      "49176/49176 [==============================] - 9s 176us/sample - loss: 0.1161 - acc: 0.9624 - val_loss: 0.1037 - val_acc: 0.9666\n",
      "Epoch 10/40\n",
      "49176/49176 [==============================] - 9s 177us/sample - loss: 0.1013 - acc: 0.9664 - val_loss: 0.0907 - val_acc: 0.9706\n",
      "Epoch 11/40\n",
      "49176/49176 [==============================] - 9s 177us/sample - loss: 0.0895 - acc: 0.9700 - val_loss: 0.0815 - val_acc: 0.9757\n",
      "Epoch 12/40\n",
      "49176/49176 [==============================] - 9s 179us/sample - loss: 0.0798 - acc: 0.9735 - val_loss: 0.0718 - val_acc: 0.9770\n",
      "Epoch 13/40\n",
      "49176/49176 [==============================] - 8s 171us/sample - loss: 0.0714 - acc: 0.9759 - val_loss: 0.0643 - val_acc: 0.9784\n",
      "Epoch 14/40\n",
      "49176/49176 [==============================] - 8s 172us/sample - loss: 0.0647 - acc: 0.9782 - val_loss: 0.0584 - val_acc: 0.9805\n",
      "Epoch 15/40\n",
      "49176/49176 [==============================] - 9s 174us/sample - loss: 0.0587 - acc: 0.9801 - val_loss: 0.0533 - val_acc: 0.9817\n",
      "Epoch 16/40\n",
      "49176/49176 [==============================] - 9s 173us/sample - loss: 0.0541 - acc: 0.9816 - val_loss: 0.0495 - val_acc: 0.9843\n",
      "Epoch 17/40\n",
      "49176/49176 [==============================] - 9s 176us/sample - loss: 0.0500 - acc: 0.9826 - val_loss: 0.0454 - val_acc: 0.9841\n",
      "Epoch 18/40\n",
      "49176/49176 [==============================] - 9s 184us/sample - loss: 0.0463 - acc: 0.9841 - val_loss: 0.0423 - val_acc: 0.9853\n",
      "Epoch 19/40\n",
      "49176/49176 [==============================] - 9s 175us/sample - loss: 0.0435 - acc: 0.9853 - val_loss: 0.0396 - val_acc: 0.9864\n",
      "Epoch 20/40\n",
      "49176/49176 [==============================] - 8s 171us/sample - loss: 0.0411 - acc: 0.9861 - val_loss: 0.0372 - val_acc: 0.9869\n",
      "Epoch 21/40\n",
      "49176/49176 [==============================] - 9s 184us/sample - loss: 0.0384 - acc: 0.9866 - val_loss: 0.0352 - val_acc: 0.9880\n",
      "Epoch 22/40\n",
      "49176/49176 [==============================] - 9s 177us/sample - loss: 0.0364 - acc: 0.9871 - val_loss: 0.0338 - val_acc: 0.9889\n",
      "Epoch 23/40\n",
      "49176/49176 [==============================] - 9s 175us/sample - loss: 0.0346 - acc: 0.9877 - val_loss: 0.0322 - val_acc: 0.9896\n",
      "Epoch 24/40\n",
      "49176/49176 [==============================] - 9s 182us/sample - loss: 0.0332 - acc: 0.9883 - val_loss: 0.0305 - val_acc: 0.9898\n",
      "Epoch 25/40\n",
      "49176/49176 [==============================] - 9s 181us/sample - loss: 0.0317 - acc: 0.9886 - val_loss: 0.0296 - val_acc: 0.9904\n",
      "Epoch 26/40\n",
      "49176/49176 [==============================] - 9s 180us/sample - loss: 0.0304 - acc: 0.9891 - val_loss: 0.0279 - val_acc: 0.9900\n",
      "Epoch 27/40\n",
      "49176/49176 [==============================] - 9s 179us/sample - loss: 0.0293 - acc: 0.9894 - val_loss: 0.0273 - val_acc: 0.9910\n",
      "Epoch 28/40\n",
      "49176/49176 [==============================] - 9s 179us/sample - loss: 0.0280 - acc: 0.9898 - val_loss: 0.0258 - val_acc: 0.9907\n",
      "Epoch 29/40\n",
      "49176/49176 [==============================] - 9s 180us/sample - loss: 0.0270 - acc: 0.9901 - val_loss: 0.0249 - val_acc: 0.9909\n",
      "Epoch 30/40\n",
      "49176/49176 [==============================] - 9s 180us/sample - loss: 0.0262 - acc: 0.9905 - val_loss: 0.0240 - val_acc: 0.9911\n",
      "Epoch 31/40\n",
      "49176/49176 [==============================] - 9s 181us/sample - loss: 0.0252 - acc: 0.9909 - val_loss: 0.0236 - val_acc: 0.9909\n",
      "Epoch 32/40\n",
      "49176/49176 [==============================] - 9s 175us/sample - loss: 0.0245 - acc: 0.9911 - val_loss: 0.0225 - val_acc: 0.9914\n",
      "Epoch 33/40\n",
      "49176/49176 [==============================] - 9s 177us/sample - loss: 0.0241 - acc: 0.9914 - val_loss: 0.0218 - val_acc: 0.9914\n",
      "Epoch 34/40\n",
      "49176/49176 [==============================] - 9s 176us/sample - loss: 0.0233 - acc: 0.9914 - val_loss: 0.0216 - val_acc: 0.9913\n",
      "Epoch 35/40\n",
      "49176/49176 [==============================] - 9s 178us/sample - loss: 0.0222 - acc: 0.9916 - val_loss: 0.0210 - val_acc: 0.9926\n",
      "Epoch 36/40\n",
      "49176/49176 [==============================] - 8s 169us/sample - loss: 0.0219 - acc: 0.9920 - val_loss: 0.0199 - val_acc: 0.9922\n",
      "Epoch 37/40\n",
      "49176/49176 [==============================] - 8s 169us/sample - loss: 0.0209 - acc: 0.9919 - val_loss: 0.0195 - val_acc: 0.9927\n",
      "Epoch 38/40\n",
      "49176/49176 [==============================] - 9s 180us/sample - loss: 0.0203 - acc: 0.9920 - val_loss: 0.0189 - val_acc: 0.9922\n",
      "Epoch 39/40\n",
      "49176/49176 [==============================] - 9s 181us/sample - loss: 0.0199 - acc: 0.9922 - val_loss: 0.0184 - val_acc: 0.9923\n",
      "Epoch 40/40\n",
      "49176/49176 [==============================] - 9s 185us/sample - loss: 0.0197 - acc: 0.9923 - val_loss: 0.0178 - val_acc: 0.9928\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,partial_y_train,epochs=40,batch_size=512,validation_data=(x_val,y_val),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.6943 - acc: 0.0740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6942797678947449, 0.074]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Testing(sentence):\n",
    "    \n",
    "    prediction_vector = []\n",
    "    temp = []\n",
    "    word_list = sentence.split(' ')\n",
    "    \n",
    "    for x in word_list:\n",
    "        \n",
    "        temp.append(total_counts[x])\n",
    "        \n",
    "    prediction_vector.append(temp)\n",
    " \n",
    "\n",
    "    vector = keras.preprocessing.sequence.pad_sequences(prediction_vector,value=0,padding='post',maxlen=971)\n",
    "    \n",
    "    a = model.predict(vector)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if(a[0][0]<0.4):\n",
    "        return(\"English Sentence\")\n",
    "    else:\n",
    "        return(\"Hinglish Sentence\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = Testing(\"what are you even talking aout man\")\n",
    "prediction2 = Testing(\"tum kya baat kar rahe ho yar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Sentence\n",
      "Hinglish Sentence\n"
     ]
    }
   ],
   "source": [
    "print(prediction1)\n",
    "print(prediction2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
